# -*- coding: utf-8 -*-
"""
Created on Thu Apr 26 07:44:50 2018

@author: ptillotson
"""

from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
import xgboost as xgb
from sklearn.svm import SVC
from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve
from sklearn.datasets import make_classification
from time import time
from sklearn.metrics import roc_auc_score
from sklearn import metrics
from sklearn.model_selection import train_test_split
from sklearn import cross_validation
import matplotlib.pyplot as plt
from sklearn.metrics import recall_score
from sklearn.metrics import precision_score
from sklearn.preprocessing import minmax_scale
from sklearn.preprocessing import MinMaxScaler
from sklearn.decomposition import RandomizedPCA
import pandas as pd
import numpy as np
import seaborn as sns
import re
import scipy.stats as stats



train_data = pd.read_csv("train.csv")
test_data = pd.read_csv("test.csv")
#train_data["Survived"] = train_data["Survived"].astype("int")
#train_data["SibSp"] = train_data["SibSp"].astype("int")
#train_data["Parch"] = train_data["Parch"].astype("int")
train_data["Embarked"] = train_data["Embarked"].astype("category")
test_data["Embarked"] = train_data["Embarked"].astype("category")
IDtest = test_data["PassengerId"]
#print(train_data.head())




train_data['Sex'].replace(['male','female'],[0,1],inplace=True)
train_data["Sex"] = train_data["Sex"].astype("int")
train_data["Embarked"].replace(["S", "C", "Q"],[0,1,2],inplace=True)
train_data.loc[(train_data.Embarked.isnull()), "Embarked"]=1
train_data["Embarked"] = train_data["Embarked"].astype("int")


test_data['Sex'].replace(['male','female'],[0,1],inplace=True)
test_data["Sex"] = test_data["Sex"].astype("int")
test_data["Embarked"].replace(["S", "C", "Q"],[0,1,2],inplace=True)
test_data.loc[(test_data.Embarked.isnull()), "Embarked"]=0
test_data["Embarked"] = test_data["Embarked"].astype("int")
    


train_data['family_size']=train_data['SibSp'] + train_data['Parch']
train_data['family_size']=train_data['family_size'].astype('int')
test_data['family_size']=test_data['SibSp'] + test_data['Parch']
test_data['family_size']=test_data['family_size'].astype('int')


train_data['Age_Missing'] = 0
train_data.loc[(train_data.Age.isnull()), 'Age_Missing']=1
test_data['Age_Missing'] = 0
test_data.loc[(train_data.Age.isnull()), 'Age_Missing']=1



#train_data.loc[(train_data['Family_size']>7), 'Family_size']=7
#test_data.loc[(test_data['Family_size']>7), 'Family_size']=7

observation_group0 = train_data.loc[(train_data['Pclass']==1)]
obs_group0_sample = train_data.Age.dropna().sample(observation_group0['Age'].isnull().sum(), random_state=0)
obs_group0_sample.index = observation_group0[observation_group0['Age'].isnull()].index
train_data.loc[(train_data['Pclass']==1) & (train_data.Age.isnull()), 'Age']=obs_group0_sample
#print(data.loc[(data['family_size']==1) & (data.Age.isnull())])

observation_group1 = train_data.loc[(train_data['Pclass']==2)]
obs_group1_sample = train_data.Age.dropna().sample(observation_group1['Age'].isnull().sum(), random_state=1)
obs_group1_sample.index = observation_group1[observation_group1['Age'].isnull()].index
train_data.loc[(train_data['Pclass']==2) & (train_data.Age.isnull()), 'Age']=obs_group1_sample
#print(data.loc[(data['family_size']==2) & (data.Age.isnull())])

observation_group2 = train_data.loc[(train_data['Pclass']==3)]
obs_group2_sample = train_data.Age.dropna().sample(observation_group2['Age'].isnull().sum(), random_state=2)
obs_group2_sample.index = observation_group2[observation_group2['Age'].isnull()].index
train_data.loc[(train_data['Pclass']==3) & (train_data.Age.isnull()), 'Age']=obs_group2_sample
#print(data.loc[(data['family_size']==3) & (data.Age.isnull())])


#print(data.loc[(data['family_size']==11) & (data.Age.isnull())])



observation_group0 = test_data.loc[(test_data['Pclass']==1)]
obs_group0_sample = test_data.Age.dropna().sample(observation_group0['Age'].isnull().sum(), random_state=0)
obs_group0_sample.index = observation_group0[observation_group0['Age'].isnull()].index
test_data.loc[(test_data['Pclass']==1) & (test_data.Age.isnull()), 'Age']=obs_group0_sample
#print(data.loc[(data['family_size']==1) & (data.Age.isnull())])

observation_group1 = test_data.loc[(test_data['Pclass']==2)]
obs_group1_sample = test_data.Age.dropna().sample(observation_group1['Age'].isnull().sum(), random_state=1)
obs_group1_sample.index = observation_group1[observation_group1['Age'].isnull()].index
test_data.loc[(test_data['Pclass']==2) & (test_data.Age.isnull()), 'Age']=obs_group1_sample
#print(data.loc[(data['family_size']==2) & (data.Age.isnull())])

observation_group2 = test_data.loc[(test_data['Pclass']==3)]
obs_group2_sample = test_data.Age.dropna().sample(observation_group2['Age'].isnull().sum(), random_state=2)
obs_group2_sample.index = observation_group2[observation_group2['Age'].isnull()].index
test_data.loc[(test_data['Pclass']==3) & (test_data.Age.isnull()), 'Age']=obs_group2_sample
#print(data.loc[(data['family_size']==3) & (data.Age.isnull())])

train_data['Age_Bin']=pd.qcut(train_data.Age, q=8, labels=False)
test_data['Age_Bin']=pd.qcut(train_data.Age, q=8, labels=False)

train_data['Age_Bin0']=0
train_data.loc[(train_data['Age_Bin']==0), 'Age_Bin0']=1
train_data['Age_Bin1']=0
train_data.loc[(train_data['Age_Bin']==1), 'Age_Bin1']=1
train_data['Age_Bin2']=0
train_data.loc[(train_data['Age_Bin']==2), 'Age_Bin2']=1
train_data['Age_Bin3']=0
train_data.loc[(train_data['Age_Bin']==3), 'Age_Bin3']=1
train_data['Age_Bin4']=0
train_data.loc[(train_data['Age_Bin']==4), 'Age_Bin4']=1
train_data['Age_Bin5']=0
train_data.loc[(train_data['Age_Bin']==5), 'Age_Bin5']=1
train_data['Age_Bin6']=0
train_data.loc[(train_data['Age_Bin']==6), 'Age_Bin6']=1
train_data['Age_Bin7']=0
train_data.loc[(train_data['Age_Bin']==7), 'Age_Bin7']=1

test_data['Age_Bin0']=0
test_data.loc[(test_data['Age_Bin']==0), 'Age_Bin0']=1
test_data['Age_Bin1']=0
test_data.loc[(test_data['Age_Bin']==1), 'Age_Bin1']=1
test_data['Age_Bin2']=0
test_data.loc[(test_data['Age_Bin']==2), 'Age_Bin2']=1
test_data['Age_Bin3']=0
test_data.loc[(test_data['Age_Bin']==3), 'Age_Bin3']=1
test_data['Age_Bin4']=0
test_data.loc[(test_data['Age_Bin']==4), 'Age_Bin4']=1
test_data['Age_Bin5']=0
test_data.loc[(test_data['Age_Bin']==5), 'Age_Bin5']=1
test_data['Age_Bin6']=0
test_data.loc[(test_data['Age_Bin']==6), 'Age_Bin6']=1
test_data['Age_Bin7']=0
test_data.loc[(test_data['Age_Bin']==7), 'Age_Bin7']=1



#Put Fare into quartile buckets since the distribution of values is skewed. 

train_data['Fare_Square'] = train_data.Fare**(1+1/1.1)
train_data['Fare_Box'], param = stats.boxcox(train_data.Fare+1)
train_data['Fare_Bin']=pd.qcut(train_data.Fare_Box, q=16, labels=False)

test_data.loc[(test_data['Fare'].isnull()), 'Fare']=13
test_data['Fare_Square'] = test_data.Fare**(1+1/1.1)
test_data['Fare_Box'], param = stats.boxcox(test_data.Fare+1)
test_data['Fare_Bin']=pd.qcut(test_data.Fare_Box, q=16, labels=False)

train_data['Fare_Bin0']=0
train_data.loc[(train_data['Fare_Bin']==0), 'Fare_Bin0']=1
train_data['Fare_Bin1']=0
train_data.loc[(train_data['Fare_Bin']==1), 'Fare_Bin1']=1
train_data['Fare_Bin2']=0
train_data.loc[(train_data['Fare_Bin']==2), 'Fare_Bin2']=1
train_data['Fare_Bin3']=0
train_data.loc[(train_data['Fare_Bin']==3), 'Fare_Bin3']=1
train_data['Fare_Bin4']=0
train_data.loc[(train_data['Fare_Bin']==4), 'Fare_Bin4']=1
train_data['Fare_Bin5']=0
train_data.loc[(train_data['Fare_Bin']==5), 'Fare_Bin5']=1
train_data['Fare_Bin6']=0
train_data.loc[(train_data['Fare_Bin']==6), 'Fare_Bin6']=1
train_data['Fare_Bin7']=0
train_data.loc[(train_data['Fare_Bin']==7), 'Fare_Bin7']=1
train_data['Fare_Bin8']=0
train_data.loc[(train_data['Fare_Bin']==8), 'Fare_Bin8']=1
train_data['Fare_Bin9']=0
train_data.loc[(train_data['Fare_Bin']==9), 'Fare_Bin9']=1
train_data['Fare_Bin10']=0
train_data.loc[(train_data['Fare_Bin']==10), 'Fare_Bin10']=1
train_data['Fare_Bin11']=0
train_data.loc[(train_data['Fare_Bin']==11), 'Fare_Bin11']=1
train_data['Fare_Bin12']=0
train_data.loc[(train_data['Fare_Bin']==12), 'Fare_Bin12']=1
train_data['Fare_Bin13']=0
train_data.loc[(train_data['Fare_Bin']==13), 'Fare_Bin13']=1
train_data['Fare_Bin14']=0
train_data.loc[(train_data['Fare_Bin']==14), 'Fare_Bin14']=1
train_data['Fare_Bin15']=0
train_data.loc[(train_data['Fare_Bin']==15), 'Fare_Bin15']=1

test_data['Fare_Bin0']=0
test_data.loc[(test_data['Fare_Bin']==0), 'Fare_Bin0']=1
test_data['Fare_Bin1']=0
test_data.loc[(test_data['Fare_Bin']==1), 'Fare_Bin1']=1
test_data['Fare_Bin2']=0
test_data.loc[(test_data['Fare_Bin']==2), 'Fare_Bin2']=1
test_data['Fare_Bin3']=0
test_data.loc[(test_data['Fare_Bin']==3), 'Fare_Bin3']=1
test_data['Fare_Bin4']=0
test_data.loc[(test_data['Fare_Bin']==4), 'Fare_Bin4']=1
test_data['Fare_Bin5']=0
test_data.loc[(test_data['Fare_Bin']==5), 'Fare_Bin5']=1
test_data['Fare_Bin6']=0
test_data.loc[(test_data['Fare_Bin']==6), 'Fare_Bin6']=1
test_data['Fare_Bin7']=0
test_data.loc[(test_data['Fare_Bin']==7), 'Fare_Bin7']=1
test_data['Fare_Bin8']=0
test_data.loc[(test_data['Fare_Bin']==8), 'Fare_Bin8']=1
test_data['Fare_Bin9']=0
test_data.loc[(test_data['Fare_Bin']==9), 'Fare_Bin9']=1
test_data['Fare_Bin10']=0
test_data.loc[(test_data['Fare_Bin']==10), 'Fare_Bin10']=1
test_data['Fare_Bin11']=0
test_data.loc[(test_data['Fare_Bin']==11), 'Fare_Bin11']=1
test_data['Fare_Bin12']=0
test_data.loc[(test_data['Fare_Bin']==12), 'Fare_Bin12']=1
test_data['Fare_Bin13']=0
test_data.loc[(test_data['Fare_Bin']==13), 'Fare_Bin13']=1
test_data['Fare_Bin14']=0
test_data.loc[(test_data['Fare_Bin']==14), 'Fare_Bin14']=1
test_data['Fare_Bin15']=0
test_data.loc[(test_data['Fare_Bin']==15), 'Fare_Bin15']=1


#train_data.loc[(train_data["Age"]>=74), 'Age']=73
#train_data['Age'] = train_data.Age**(1/1.2)
#test_data.loc[(test_data["Age"]>=74), 'Age']=73
#test_data['Age'] = train_data.Age**(1/1.2)

##Rare title work such as Mr. and Mrs.
##Names have unique titles such as Mrs or Mr. Let's extract that and place it into a new column.
def get_title(passenger):
    line = passenger
    if re.search('Mrs', line):
        return 'Mrs'
    elif re.search('Mr', line):
        return 'Mr'
    elif re.search('Miss', line):
        return 'Miss'
    elif re.search('Master', line):
        return 'Master'
    else:
        return 'Other'
##Add title column to train_data with title (i.e. Mr or Mrs)  
train_data['Title'] = train_data['Name'].apply(get_title)
##Convert Title to a number representing the Title
train_data['Title0'] = 0
train_data.loc[(train_data["Title"]=="Mrs"), 'Title0']=1
train_data['Title1'] = 0
train_data.loc[(train_data["Title"]=="Mr"), 'Title1']=1
train_data['Title2'] = 0
train_data.loc[(train_data["Title"]=="Miss"), 'Title2']=1
train_data['Title3'] = 0
train_data.loc[(train_data["Title"]=="Master"), 'Title3']=1
train_data['Title4'] = 0
train_data.loc[(train_data["Title"]=="Other"), 'Title4']=1
#train_data['Title'] = train_data['Title'].astype('int')
train_data.drop(['Title'],axis=1,inplace=True)

##Add title column to train_data with title (i.e. Mr or Mrs)  
test_data['Title'] = test_data['Name'].apply(get_title)
##Convert Title to a number representing the Title
test_data['Title0']=0
test_data.loc[(test_data["Title"]=="Mrs"), 'Title0']=1
test_data['Title1']=0
test_data.loc[(test_data["Title"]=="Mr"), 'Title1']=1
test_data['Title2']=0
test_data.loc[(test_data["Title"]=="Miss"), 'Title2']=1
test_data['Title3']=0
test_data.loc[(test_data["Title"]=="Master"), 'Title3']=1
test_data['Title4']=0
test_data.loc[(test_data["Title"]=="Other"), 'Title4']=1
#test_data['Title'] = train_data['Title'].astype('int')
test_data.drop(['Title'],axis=1,inplace=True)

train_data['Pclass1'] = 0
train_data.loc[(train_data['Pclass']==1), 'Pclass1']=1
train_data['Pclass3'] = 0
train_data.loc[(train_data['Pclass']==3), 'Pclass3']=1


test_data['Pclass1'] = 0
test_data.loc[(test_data['Pclass']==1), 'Pclass1']=1
test_data['Pclass3'] = 0
test_data.loc[(test_data['Pclass']==3), 'Pclass3']=1

train_data['Cabin_Missing'] = 0
train_data.loc[(train_data.Cabin.isnull()), 'Cabin_Missing']=1
test_data['Cabin_Missing'] = 0
test_data.loc[(test_data.Cabin.isnull()), 'Cabin_Missing']=1

train_data['Female']=0
train_data.loc[(train_data['Sex']==1), 'Female']=1
test_data['Female']=0
test_data.loc[(test_data['Sex']==1), 'Female']=1

train_data['Male']=0
train_data.loc[(train_data['Sex']==0), 'Male']=1
test_data['Male']=0
test_data.loc[(test_data['Sex']==0), 'Male']=1

train_data['Cabin_Letter'] = train_data['Cabin'].apply(lambda x: str(x)[0])
test_data['Cabin_Letter'] = test_data['Cabin'].apply(lambda x: str(x)[0])
print(train_data['Cabin_Letter'].value_counts())


train_data['Cabin_C']=0
train_data.loc[(train_data['Cabin_Letter']=='C'), 'Cabin_C']=1
train_data['Cabin_B']=0
train_data.loc[(train_data['Cabin_Letter']=='B'), 'Cabin_B']=1
train_data['Cabin_D']=0
train_data.loc[(train_data['Cabin_Letter']=='D'), 'Cabin_D']=1
train_data['Cabin_E']=0
train_data.loc[(train_data['Cabin_Letter']=='E'), 'Cabin_E']=1
train_data['Cabin_A']=0
train_data.loc[(train_data['Cabin_Letter']=='A'), 'Cabin_A']=1
train_data['Cabin_F']=0
train_data.loc[(train_data['Cabin_Letter']=='F'), 'Cabin_F']=1
train_data['Cabin_G']=0
train_data.loc[(train_data['Cabin_Letter']=='G'), 'Cabin_G']=1
train_data['Cabin_T']=0
train_data.loc[(train_data['Cabin_Letter']=='T'), 'Cabin_T']=1

test_data['Cabin_C']=0
test_data.loc[(test_data['Cabin_Letter']=='C'), 'Cabin_C']=1
test_data['Cabin_B']=0
test_data.loc[(test_data['Cabin_Letter']=='B'), 'Cabin_B']=1
test_data['Cabin_D']=0
test_data.loc[(test_data['Cabin_Letter']=='D'), 'Cabin_D']=1
test_data['Cabin_E']=0
test_data.loc[(test_data['Cabin_Letter']=='E'), 'Cabin_E']=1
test_data['Cabin_A']=0
test_data.loc[(test_data['Cabin_Letter']=='A'), 'Cabin_A']=1
test_data['Cabin_F']=0
test_data.loc[(test_data['Cabin_Letter']=='F'), 'Cabin_F']=1
test_data['Cabin_G']=0
test_data.loc[(test_data['Cabin_Letter']=='G'), 'Cabin_G']=1
test_data['Cabin_T']=0
test_data.loc[(test_data['Cabin_Letter']=='T'), 'Cabin_T']=1




print(train_data.head(1))
test_data.drop(['Name', 'Ticket', 'Cabin', 'PassengerId', 'Cabin_Letter', 'Age_Bin0', 'Sex', 'Male', 'Pclass', 'Age_Bin', 'Fare', 'Age', 'Fare_Square', 'Cabin_Missing', 'Fare_Box', 'Fare_Bin', 'Age_Missing', 'SibSp', 'Parch'],axis=1,inplace=True)
train_data.drop(['Name', 'Ticket', 'Cabin', 'PassengerId', 'Cabin_Letter', 'Age_Bin0', 'Sex', 'Male', 'Pclass', 'Age_Bin', 'Fare', 'Age', 'Fare_Square', 'Cabin_Missing', 'Fare_Box', 'Fare_Bin', 'Age_Missing', 'SibSp', 'Parch'],axis=1,inplace=True)
scaler = MinMaxScaler()
train_data[['family_size', 'Female', 'Pclass1', 'Age_Bin1', 'Age_Bin2', 'Age_Bin3', 'Age_Bin4', 'Age_Bin5', 'Age_Bin6', 'Age_Bin7', 'Embarked', 'Pclass3', 'Cabin_T', 'Cabin_F', 'Cabin_G', 'Cabin_E', 'Cabin_A', 'Cabin_B', 'Cabin_C', 'Cabin_D', 'Fare_Bin1', 'Fare_Bin2', 'Fare_Bin3', 'Fare_Bin4', 'Fare_Bin5', 'Fare_Bin6', 'Fare_Bin7', 'Fare_Bin8', 'Fare_Bin9', 'Fare_Bin10', 'Fare_Bin11', 'Fare_Bin12', 'Fare_Bin13', 'Fare_Bin14', 'Fare_Bin15', 'Title0', 'Title1', 'Title2', 'Title3']] = scaler.fit_transform(train_data[['family_size', 'Female', 'Pclass1', 'Age_Bin1', 'Age_Bin2', 'Age_Bin3', 'Age_Bin4', 'Age_Bin5', 'Age_Bin6', 'Age_Bin7', 'Embarked', 'Pclass3', 'Cabin_T', 'Cabin_F', 'Cabin_G', 'Cabin_E', 'Cabin_A', 'Cabin_B', 'Cabin_C', 'Cabin_D', 'Fare_Bin1', 'Fare_Bin2', 'Fare_Bin3', 'Fare_Bin4', 'Fare_Bin5', 'Fare_Bin6', 'Fare_Bin7', 'Fare_Bin8', 'Fare_Bin9', 'Fare_Bin10', 'Fare_Bin11', 'Fare_Bin12', 'Fare_Bin13', 'Fare_Bin14', 'Fare_Bin15', 'Title0', 'Title1', 'Title2', 'Title3']])
test_data[['family_size', 'Female', 'Pclass1', 'Age_Bin1', 'Age_Bin2', 'Age_Bin3', 'Age_Bin4', 'Age_Bin5', 'Age_Bin6', 'Age_Bin7', 'Embarked', 'Pclass3', 'Cabin_T', 'Cabin_F', 'Cabin_G', 'Cabin_E', 'Cabin_A', 'Cabin_B', 'Cabin_C', 'Cabin_D', 'Fare_Bin1', 'Fare_Bin2', 'Fare_Bin3', 'Fare_Bin4', 'Fare_Bin5', 'Fare_Bin6', 'Fare_Bin7', 'Fare_Bin8', 'Fare_Bin9', 'Fare_Bin10', 'Fare_Bin11', 'Fare_Bin12', 'Fare_Bin13', 'Fare_Bin14', 'Fare_Bin15', 'Title0', 'Title1', 'Title2', 'Title3']] = scaler.transform(test_data[['family_size', 'Female', 'Pclass1', 'Age_Bin1', 'Age_Bin2', 'Age_Bin3', 'Age_Bin4', 'Age_Bin5', 'Age_Bin6', 'Age_Bin7', 'Embarked', 'Pclass3', 'Cabin_T', 'Cabin_F', 'Cabin_G', 'Cabin_E', 'Cabin_A', 'Cabin_B', 'Cabin_C', 'Cabin_D', 'Fare_Bin1', 'Fare_Bin2', 'Fare_Bin3', 'Fare_Bin4', 'Fare_Bin5', 'Fare_Bin6', 'Fare_Bin7', 'Fare_Bin8', 'Fare_Bin9', 'Fare_Bin10', 'Fare_Bin11', 'Fare_Bin12', 'Fare_Bin13', 'Fare_Bin14', 'Fare_Bin15', 'Title0', 'Title1', 'Title2', 'Title3']])
print(train_data.head(1))

train,test=cross_validation.train_test_split(train_data,test_size=0.20,random_state=42,stratify=train_data['Survived'])
features_train=train[train.columns[1:]]
labels_train=train[train.columns[:1]]
features_test=test[test.columns[1:]]
labels_test=test[test.columns[:1]]
features=train_data[train_data.columns[1:]]
labels=train_data['Survived']



import keras
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Dropout
from keras.wrappers.scikit_learn import KerasClassifier
from sklearn.model_selection import GridSearchCV

annc = Sequential()
##Hidden layer
annc.add(Dense(output_dim = 20, init = 'uniform', activation = 'relu', input_dim = 41))
#classifier.add(Dropout(p = 0.1))
##Second hidden layer
annc.add(Dense(output_dim = 20, init = 'uniform', activation = 'relu'))
#classifier.add(Dropout(p = 0.1))
##Output layer
annc.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))
##Compiling
annc.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])
##Fit
annc.fit(features_train, labels_train, batch_size = 10, epochs = 875)

anncpred = annc.predict(features_test)


test_survived_answers = annc.predict(test_data)
test_survived = pd.DataFrame(data=test_survived_answers, columns = ['Survived'])
results = pd.concat([IDtest,test_survived],axis=1)
results.to_csv("submit_to_kaggle4.csv",index=False)
test_survived.loc[(test_survived['Survived']>0.60), 'Survived']=1
test_survived.loc[(test_survived['Survived']!=1), 'Survived']=0
#test_survived = pd.Series(test_survived[0:], name="Survived")
results = pd.concat([IDtest,test_survived],axis=1)
results.to_csv("submit_to_kaggle3.csv",index=False)


##Enable if not tunning
#def build_classifier():
##Enable if tuning
#def build_classifier(optimizer):
 #   classifier = Sequential()
  #  classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu', input_dim = 12))
    #classifier.add(Dropout(p = 0.1))
   # classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu'))
    #classifier.add(Dropout(p = 0.1))
   # classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))
    #classifier.compile(optimizer = optimizer loss = 'binary_crossentropy', metrics = ['accuracy'])
    #return classifier
#classifier = KerasClassifier(build_fn = build_classifier, batch_size = 1, epochs = 500)
##Disable if tuning
#accuracies = cross_val_score(estimator = classifier,  X = features_train, y = labels_train, cv = 10, n_jobs = 1)
#parameters = {'batch_size': [25, 32], 
 #             'epochs': [100, 500], 
  #            'optimizer': ['adam', 'rmsprop']}
#grid_search = GridSearchCV(estimator = classifier,
 #                          param_grid = parameters,
  #                         scoring = 'accuracy',
   #                        cv = 10)
#grid_search = grid_search.fit(features_train, labels_train)
#best_parameters = grid_search.best_params_
#best_accruacy = grid_search.best_score_

#print(best_parameters)
#print(best_accruacy)

#annpred = classifier.predict(features_test)

# Making the Confusion Matrix
   
#import keras
#from keras.models import Sequential
#from keras.layers import Dense
#from keras.layers import Dropout
#from keras.wrappers.scikit_learn import KerasClassifier
#from sklearn.model_selection import GridSearchCV

#def build_classifier():
#def build_classifier(optimizer):
 #   annc = Sequential()
  #  annc.add(Dense(output_dim = 13, init = 'uniform', activation = 'relu', input_dim = 26))
    #classifier.add(Dropout(p = 0.1))
   # annc.add(Dense(output_dim = 13, init = 'uniform', activation = 'relu'))
    #classifier.add(Dropout(p = 0.1))
    #annc.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))
    #annc.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])
    #return annc
#annc = KerasClassifier(build_fn = build_classifier, batch_size = 1, epochs = 875)
#accuracies = cross_val_score(estimator = annc, X = features_train, y = labels_train, cv = 10, n_jobs = 1)


#test_Survived = pd.Series(votingC.predict(test_data), name="Survived")
#results = pd.concat([IDtest,test_Survived],axis=1)
#results.to_csv("submit_to_kaggle2.csv",index=False)
#results.to_csv("submit_to_kaggle.csv",index=False)
    
    

